
Namespace(activation='leaky_relu', arch='resnet18', batch_size=64, cls_num=0, cls_size=10, config='configs/test.yaml', data='cifar10/cifar10', dim=128, hidden_dim=4096, kmeans_cls=None, model='self-classifier', num_classes=10, num_hidden=1, num_samples_per_class=16, pretrained='saved/cifar10/100epochs/adam/model_best.pth.tar', print_freq=10, save_path='../saved/results/', seed=None, subset_file=None, tau=0.1, use_bn=True)
=> creating model 'resnet18'
Model(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Identity()
  )
  (classifier_head): MLPhead(
    (mlp): Linear(in_features=512, out_features=128, bias=True)
  )
  (classifier_final): Linear(in_features=128, out_features=10, bias=False)
)
=> loading checkpoint 'saved/cifar10/100epochs/adam/model_best.pth.tar'
=> loaded pre-trained model 'saved/cifar10/100epochs/adam/model_best.pth.tar' (epoch 99)
=> using 1 GPUs.
Test: [  0/157]	Time  1.436 ( 1.436)
Test: [ 10/157]	Time  0.165 ( 0.288)
Test: [ 20/157]	Time  0.164 ( 0.230)
Test: [ 30/157]	Time  0.175 ( 0.210)
Test: [ 40/157]	Time  0.171 ( 0.210)
Test: [ 50/157]	Time  0.165 ( 0.202)
Test: [ 60/157]	Time  0.168 ( 0.196)
Test: [ 70/157]	Time  0.169 ( 0.192)
Test: [ 80/157]	Time  0.166 ( 0.189)
Test: [ 90/157]	Time  0.176 ( 0.188)
Test: [100/157]	Time  0.167 ( 0.186)
Test: [110/157]	Time  0.166 ( 0.184)
Test: [120/157]	Time  0.186 ( 0.183)
Test: [130/157]	Time  0.168 ( 0.182)
Test: [140/157]	Time  0.168 ( 0.181)
Test: [150/157]	Time  0.165 ( 0.180)
=> number of samples: 10000
=> number of unique assignments: 10
=> NMI: 48.409%
=> Adjusted NMI: 48.318%
=> Adjusted Rand-Index: 32.501%
=> Accuracy: 49.760%
=> saved grid_0.pdf, accuracy = 0.967, nsamples = 635
=> grid 0 labels: [1 1 1 1 1 1 1 1 1 1 8 1 1 1 1 1]
=> saved grid_1.pdf, accuracy = 0.865, nsamples = 732
=> grid 1 labels: [9 9 1 1 9 9 9 9 9 1 1 9 1 9 9 9]
=> saved grid_2.pdf, accuracy = 0.587, nsamples = 968
=> grid 2 labels: [8 0 0 8 1 0 8 0 4 8 0 8 8 8 8 8]
=> saved grid_3.pdf, accuracy = 0.573, nsamples = 1164
=> grid 3 labels: [6 6 2 6 6 6 2 6 6 6 4 6 6 5 2 6]
=> saved grid_4.pdf, accuracy = 0.543, nsamples = 1114
=> grid 4 labels: [7 7 3 7 5 5 5 6 7 4 5 5 5 5 3 5]
=> saved grid_5.pdf, accuracy = 0.509, nsamples = 1126
=> grid 5 labels: [8 0 8 8 0 2 8 2 8 8 3 0 0 2 8 0]
=> saved grid_6.pdf, accuracy = 0.474, nsamples = 1272
=> grid 6 labels: [7 7 4 4 4 7 7 7 4 7 2 7 4 4 4 2]
=> saved grid_7.pdf, accuracy = 0.322, nsamples = 1024
=> grid 7 labels: [6 2 2 4 3 0 3 5 6 5 3 3 4 3 3 7]
=> saved grid_8.pdf, accuracy = 0.306, nsamples = 1251
=> grid 8 labels: [3 5 2 5 0 6 2 2 4 6 2 2 2 0 2 3]
=> saved grid_9.pdf, accuracy = 0.000, nsamples = 714
=> grid 9 labels: [8 1 1 1 9 9 9 1 8 1 1 1 9 9 9 1]
